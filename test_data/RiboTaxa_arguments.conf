##The configuration file is very important and each parameter needs to be filled to avoid errors.
##Obligatory parameters are denoted by **

#-----------------------
#Setting up directories
#-----------------------

[BASE]
####set up RiboTaxa directory **
RiboTaxa_DIR = ~/RiboTaxa

####set up data directory containing only raw reads in fastq/fastq.gz format
###paired-end files should be metagenome_R1.fastq/fastq.gz and metagenome_R2.fastq/fastq.gz
###singled-end file should be metagenome.fastq/fastq.gz
DATA_DIR = ~/RiboTaxa/test_data/raw_data

####format of your paired end files **
## fastq : if files are not compressed
## fastq.gz: if files are compressed in gz format
FORMAT = fastq.gz

####set up output directory **
OUTPUT = ~/RiboTaxa/test_data

####number of threads/CPUS to be used through the pipeline 
THREAD = 8

[BBMAP]
##RAM Limit to be used by BBTOOLS/BBMAP during quality control and mapping 
##depends of the computer RAM. Use approx 80% of available RAM
##exemple: Available RAM = 16GB, therefore RAM = 80/100*16 = 12GB
RAM = 12

#-----------------------------
#Quality control using BBTOOLS
#-----------------------------

####Trim reads to remove bases matching reference kmers
# f (don't trim)
# r (trim to the right)
# l (trim to the left)

ktrim = r

####Kmer length used for finding contaminants
kmer = 21

####Reads shorter than this after trimming will be discarded
minlength = 60

#Regions with average quality BELOW this will be trimmed
trimq = 20

####Trim read ends to remove bases with quality below trimq
# rl (trim both ends), 
# f (neither end), 
# r (right end only), 
# l (left end only),
# w (sliding window)

qtrim = rl

####reads with more Ns than this (after trimming) will be discarded
maxns = 1

#------------------------------------
#Filter 16S/18S reads using SortmeRNA
#------------------------------------

####indexed database directory for sortmerna **
##This directory should contain one .clustered.fasta and several .clustered. files
SORTMERNA_DB = ~/Documents/Databases/sortmerna_indexed_DB


#----------------------------------------------------------
#Reconstructing 16S/18S sequences using EMIRGE and MetaRIB
#----------------------------------------------------------

[EMIRGE]

####set up database directory containing indexed files for emirge **
##This directory should contain one fasta file and several .ebwt files
EMIRGE_DB = ~/Documents/Databases/SILVA_p1600_e1900/bowtie_indexed_DB

####length of longest reads **
MAX_LENGTH = 300

####identity
IDENTITY = 1 

####number of iterations (Default value = 40)
NUM_ITERATION = 20

####mean insert size
MEAN_INSERT_SIZE = 300 

####standard deviation
STD_DEV = 100 


####minimum fraction of the length of a candidate
####reference sequence that must be covered by mapped
####reads (Default=0.3) Range [0.0,1.0]
MIN_COV = 0.3

[METARIB]
SAMPLING_NUM = 1000000

#-----------------------------------------------------------
#Taxonomic classfication using sklearn_classifier of qiime2
#-----------------------------------------------------------

####set up path+database name for sklearn classifier **
SKLEARN_DB = ~/Documents/Databases/qiime2020.8_silva138/silva-138-99-nb-classifier.qza

#Confidence threshold for limiting taxonomic depth (default = 0.7)
CONFIDENCE = 0.7

#Number of reads to process in each batch (default = auto: 20 000 sequences)
#use BATCH = 1 if you have less than 16GB RAM to avoid errors
BATCH = auto



